{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class={0:\"Normal\",1:\"Tuberculosis\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_dir=Path(\"TB_Chest_Radiography_Database/Normal/\")\n",
    "TB_dir=Path(\"TB_Chest_Radiography_Database/Tuberculosis/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_images:list=natsorted(list(map(str, list(Normal_dir.glob(\"*.png\")))))\n",
    "TB_images:list=natsorted(list(map(str, list(TB_dir.glob(\"*.png\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_labels:list=[0]*len(Normal_images)\n",
    "TB_labels:list=[1]*len(TB_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array(Normal_images+TB_images)\n",
    "labels=np.array(Normal_labels+TB_labels)\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(images,labels,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1=x_train[0]\n",
    "image_1=cv2.imread(image_1)\n",
    "lab=cv2.cvtColor(image_1,cv2.COLOR_BGR2LAB)\n",
    "clahe=cv2.createCLAHE(2,(16,16))\n",
    "lab[:, :, 0]=clahe.apply(lab[:, :, 0])\n",
    "image_1_equalized=cv2.cvtColor(lab,cv2.COLOR_LAB2BGR)\n",
    "image_1_equalized=cv2.cvtColor(image_1_equalized,cv2.COLOR_BGR2RGB)\n",
    "image_1=cv2.cvtColor(image_1,cv2.COLOR_BGR2RGB)\n",
    "_, ax = plt.subplots(1, 2, figsize=(7, 7))\n",
    "ax[0].imshow(image_1)\n",
    "ax[0].set_title(\"Before CLAHE\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(image_1_equalized)\n",
    "ax[1].set_title(\"After CLAHE\")\n",
    "ax[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(path):\n",
    "    img=cv2.imread(path)\n",
    "    img=cv2.cvtColor(image_1,cv2.COLOR_BGR2LAB)\n",
    "    clahe=cv2.createCLAHE(2,(16,16))\n",
    "    img[:, :, 0]=clahe.apply(img[:, :, 0])\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_LAB2BGR)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    img=cv2.resize(img,(128,128))\n",
    "    img=img/255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(list(map(image_preprocessing,x_train)))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid=np.array(list(map(image_preprocessing,x_valid)))\n",
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train)).batch(10).prefetch(tf.data.AUTOTUNE)\n",
    "validation_dataset=tf.data.Dataset.from_tensor_slices((x_valid,y_valid)).batch(10).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 10, figsize=(14, 4))\n",
    "for batch in train_dataset.take(10):\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(10):\n",
    "        img = (images[i]*255).numpy().astype(\"uint8\")\n",
    "        label=labels[i].numpy()\n",
    "        ax[i].imshow(img)\n",
    "        ax[i].set_title(target_class[label])\n",
    "        ax[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 10, figsize=(14, 4))\n",
    "for batch in validation_dataset.take(10):\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(10):\n",
    "        img = (images[i]*255).numpy().astype(\"uint8\")\n",
    "        label=labels[i].numpy()\n",
    "        ax[i].imshow(img)\n",
    "        ax[i].set_title(target_class[label])\n",
    "        ax[i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_valid[np.random.choice(range(x_valid.shape[0]))]\n",
    "plt.imshow((image*255).astype(\"uint8\"))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "image=tf.convert_to_tensor([image])\n",
    "\n",
    "patches = Patches(16)(image)\n",
    "print(f\"Image size: {256} X {256}\")\n",
    "print(f\"Patch size: {16} X {16}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (16, 16, 3))\n",
    "    plt.imshow((patch_img*255).numpy().astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = keras.layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = keras.layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units):\n",
    "    for units in hidden_units:\n",
    "        x = keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    inputs=keras.layers.Input(shape=(128,128,3))\n",
    "    patches=Patches(16)(inputs)\n",
    "    encoded=PatchEncoder(64,768)(patches)\n",
    "    for _ in range(12):\n",
    "        x1=keras.layers.LayerNormalization()(encoded)\n",
    "        attention=keras.layers.MultiHeadAttention(num_heads=12,key_dim=768)(x1,x1)\n",
    "        x2=keras.layers.Add()([attention,encoded])\n",
    "        x3=keras.layers.LayerNormalization()(x2)\n",
    "        x3=mlp(x3,[768])\n",
    "        encoded=keras.layers.Add()([x3,x2])\n",
    "    rep=keras.layers.Flatten()(encoded)\n",
    "    rep=mlp(rep,hidden_units=[3072])\n",
    "    output=keras.layers.Dense(1,activation='sigmoid')(rep)\n",
    "\n",
    "    model=keras.Model(inputs=inputs,outputs=output)\n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=keras.metrics.Recall())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(train_dataset,validation_data=validation_dataset,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
