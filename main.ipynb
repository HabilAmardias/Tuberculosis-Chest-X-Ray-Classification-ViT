{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from pathlib import Path\n",
    "from natsort import natsorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "patch_size=16\n",
    "img_size=128\n",
    "num_patches=(img_size//patch_size)**2\n",
    "p_dim=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class={0:\"Normal\",1:\"Tuberculosis\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_dir=Path(\"TB_Chest_Radiography_Database/Normal/\")\n",
    "TB_dir=Path(\"TB_Chest_Radiography_Database/Tuberculosis/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_images:list=natsorted(list(map(str, list(Normal_dir.glob(\"*.png\")))))\n",
    "TB_images:list=natsorted(list(map(str, list(TB_dir.glob(\"*.png\")))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Normal_labels:list=[0]*len(Normal_images)\n",
    "TB_labels:list=[1]*len(TB_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.array(Normal_images+TB_images)\n",
    "labels=np.array(Normal_labels+TB_labels)\n",
    "images.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(images,labels,test_size=0.2,random_state=42)\n",
    "x_valid,x_test,y_valid,y_test=train_test_split(x_valid,y_valid,test_size=0.5,random_state=42)\n",
    "(x_train.shape,x_valid.shape,x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1=x_train[0]\n",
    "image_1=cv2.imread(image_1)\n",
    "image_1=cv2.cvtColor(image_1,cv2.COLOR_BGR2GRAY)\n",
    "clahe=cv2.createCLAHE(2,(16,16))\n",
    "image_1_equalized=clahe.apply(image_1)\n",
    "image_1_equalized_blurred=cv2.GaussianBlur(image_1_equalized,(5,5),0)\n",
    "_, ax = plt.subplots(1, 2, figsize=(7, 7))\n",
    "ax[0].imshow(image_1,cmap='gray')\n",
    "ax[0].set_title(\"Before CLAHE + Gaussian Blur\")\n",
    "ax[0].axis(\"off\")\n",
    "ax[1].imshow(image_1_equalized_blurred,cmap='gray')\n",
    "ax[1].set_title(\"After CLAHE + Gaussian Blur\")\n",
    "ax[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(path):\n",
    "    img=cv2.imread(path)\n",
    "    img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    clahe=cv2.createCLAHE(3,(16,16))\n",
    "    img=clahe.apply(img)\n",
    "    img=cv2.GaussianBlur(img,(5,5),0)\n",
    "    img=cv2.resize(img,(img_size,img_size))\n",
    "    img=img.reshape(img_size,img_size,1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import albumentations as alb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "augmentation=alb.Compose([\n",
    "    alb.RandomBrightnessContrast(brightness_limit=0,contrast_limit=0.1,p=0.5),\n",
    "    alb.Rotate(limit=5,interpolation=cv2.INTER_LINEAR,p=0.5),\n",
    "    alb.Affine(translate_percent=0.1,interpolation=cv2.INTER_LINEAR,p=0.5),\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for path in x_train[y_train==1]:\n",
    "    img=cv2.imread(path)\n",
    "    try:\n",
    "        for x in range(2):\n",
    "            augmented=augmentation(image=img)\n",
    "            modified_path=path.split(\"\\\\\")[2]\n",
    "            cv2.imwrite(f'augmented_images/{modified_path.split(\".\")[0]}-{x}.png',augmented['image'])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_dir=Path(\"augmented_images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_images=list(map(str, list(augmented_dir.glob(\"*.png\"))))\n",
    "augmented_labels=[1]*len(augmented_images)\n",
    "augmented_images=np.array(augmented_images)\n",
    "augmented_labels=np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.concatenate((x_train,augmented_images))\n",
    "y_train=np.concatenate((y_train,augmented_labels))\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.array(list(map(image_preprocessing,x_train)))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid=np.array(list(map(image_preprocessing,x_valid)))\n",
    "x_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=np.array(list(map(image_preprocessing,x_test)))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=tf.data.Dataset.from_tensor_slices((x_train,y_train)).shuffle(5000,seed=42).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "validation_dataset=tf.data.Dataset.from_tensor_slices((x_valid,y_valid)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset=tf.data.Dataset.from_tensor_slices((x_test,y_test)).batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 5, figsize=(14, 7))\n",
    "for batch in train_dataset.take(1):\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(batch_size):\n",
    "        img = (images[i]*255).numpy().astype(\"uint8\")\n",
    "        label=labels[i].numpy()\n",
    "        ax[i//5,i%5].imshow(img,cmap='gray')\n",
    "        ax[i//5,i%5].set_title(target_class[label])\n",
    "        ax[i//5,i%5].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 5, figsize=(14, 7))\n",
    "for batch in validation_dataset.take(1):\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(batch_size):\n",
    "        img = (images[i]*255).numpy().astype(\"uint8\")\n",
    "        label=labels[i].numpy()\n",
    "        ax[i//5,i%5].imshow(img,cmap='gray')\n",
    "        ax[i//5,i%5].set_title(target_class[label])\n",
    "        ax[i//5,i%5].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(2, 5, figsize=(14, 7))\n",
    "for batch in test_dataset.take(1):\n",
    "    images = batch[0]\n",
    "    labels = batch[1]\n",
    "    for i in range(batch_size):\n",
    "        img = (images[i]*255).numpy().astype(\"uint8\")\n",
    "        label=labels[i].numpy()\n",
    "        ax[i//5,i%5].imshow(img,cmap='gray')\n",
    "        ax[i//5,i%5].set_title(target_class[label])\n",
    "        ax[i//5,i%5].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patches(keras.layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "    \n",
    "    def get_config(self):\n",
    "        config=super().get_config()\n",
    "        config.update({\n",
    "            \"patch_size\":self.patch_size\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "image = x_valid[np.random.choice(range(x_valid.shape[0]))]\n",
    "plt.imshow((image*255).astype(\"uint8\"),cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "image=tf.convert_to_tensor([image])\n",
    "\n",
    "patches = Patches(patch_size)(image)\n",
    "print(f\"Image size: {img_size} X {img_size}\")\n",
    "print(f\"Patch size: {patch_size} X {patch_size}\")\n",
    "print(f\"Patches per image: {patches.shape[1]}\")\n",
    "print(f\"Elements per patch: {patches.shape[-1]}\")\n",
    "\n",
    "n = int(np.sqrt(patches.shape[1]))\n",
    "plt.figure(figsize=(4, 4))\n",
    "for i, patch in enumerate(patches[0]):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    patch_img = tf.reshape(patch, (patch_size, patch_size, 1))\n",
    "    plt.imshow((patch_img*255).numpy().astype(\"uint8\"),cmap='gray')\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEncoder(keras.layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super().__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection_dim=projection_dim\n",
    "        self.projection = keras.layers.Dense(units=self.projection_dim)\n",
    "        self.position_embedding = keras.layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=self.projection_dim\n",
    "        )\n",
    "    \n",
    "    def get_config(self):\n",
    "        config=super().get_config()\n",
    "        config.update({\n",
    "            \"num_patches\":self.num_patches,\n",
    "            \"projection_dim\":self.projection_dim\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, hidden_units):\n",
    "    for units in hidden_units:\n",
    "        x = keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    inputs=keras.layers.Input(shape=(img_size,img_size,1))\n",
    "    patches=Patches(patch_size)(inputs)\n",
    "    encoded=PatchEncoder(num_patches,p_dim)(patches)\n",
    "    heads_att=hp.Int(\"n_self_heads\",min_value=2,max_value=6,step=2)\n",
    "    num_encoder=hp.Int(\"n_encoders\",min_value=6,max_value=12,step=3)\n",
    "    for _ in range(num_encoder):\n",
    "        x1=keras.layers.LayerNormalization()(encoded)\n",
    "        attention=keras.layers.MultiHeadAttention(num_heads=heads_att,key_dim=p_dim)(x1,x1)\n",
    "        x2=keras.layers.Add()([attention,encoded])\n",
    "        x3=keras.layers.LayerNormalization()(x2)\n",
    "        x3=mlp(x3,[2*p_dim,p_dim])\n",
    "        encoded=keras.layers.Add()([x3,x2])\n",
    "    rep=keras.layers.GlobalAveragePooling1D()(encoded)\n",
    "    mlp_head=hp.Int(\"n_mlp_head\",min_value=1024,max_value=3072,step=1024)\n",
    "    rep=mlp(rep,hidden_units=[mlp_head,mlp_head//2])\n",
    "    output=keras.layers.Dense(1,activation='sigmoid')(rep)\n",
    "\n",
    "    model=keras.Model(inputs=inputs,outputs=output)\n",
    "    opt = keras.optimizers.Adam()\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=keras.losses.BinaryFocalCrossentropy(),\n",
    "                  metrics=[keras.metrics.Recall(),\n",
    "                           keras.metrics.BinaryAccuracy()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner=kt.GridSearch(build_model,objective=kt.Objective('val_loss','min'))\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop=keras.callbacks.EarlyStopping(monitor='val_loss',restore_best_weights=False,patience=10)\n",
    "lr_scheduler=keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=3,verbose=1,min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.search(train_dataset,\n",
    "             batch_size=batch_size,\n",
    "             epochs=50,\n",
    "             validation_data=validation_dataset,\n",
    "             callbacks=[early_stop,lr_scheduler])\n",
    "model=tuner.get_best_models()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras.utils.plot_model(model,show_layer_activations=True,show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop=keras.callbacks.EarlyStopping(monitor='val_loss',restore_best_weights=True,patience=20)\n",
    "lr_scheduler=keras.callbacks.ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5,verbose=1,min_lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_dataset,\n",
    "                  validation_data=validation_dataset,\n",
    "                  epochs=200,\n",
    "                  callbacks=[early_stop,lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, ax = plt.subplots(1, 3, figsize=(20,7))\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "recall=history.history['recall']\n",
    "val_recall=history.history['val_recall']\n",
    "binary_accuracy=history.history['binary_accuracy']\n",
    "val_binary_accuracy=history.history['val_binary_accuracy']\n",
    "epochs = range(len(loss))\n",
    "\n",
    "ax[0].plot(epochs, loss)\n",
    "ax[0].plot(epochs, val_loss)\n",
    "ax[0].legend(['loss', 'val_loss'], loc='upper right')\n",
    "\n",
    "ax[1].plot(epochs, recall)\n",
    "ax[1].plot(epochs, val_recall)\n",
    "ax[1].legend(['recall', 'val_recall'], loc='upper right')\n",
    "\n",
    "ax[2].plot(epochs, binary_accuracy)\n",
    "ax[2].plot(epochs, val_binary_accuracy)\n",
    "ax[2].legend(['binary_accuracy', 'val_binary_accuracy'], loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val=model.predict(validation_dataset)\n",
    "y_pred_val=np.round(y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test=model.predict(test_dataset)\n",
    "y_pred_test=np.round(y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "\n",
    "def evaluation_parametrics(name,y_val, y_pred):\n",
    "    \n",
    "    print(\"\\n------------------------{}------------------------\\n\".format(name))\n",
    "\n",
    "    cm_test = confusion_matrix(y_val, y_pred)\n",
    "    t1 = ConfusionMatrixDisplay(cm_test)    \n",
    "    print(\"\\nClassification Report for Data Validation\\n\")\n",
    "    print(classification_report(y_val, y_pred))   \n",
    "    print(\"--------------------------------------------------------------------------\")\n",
    "\n",
    "    t1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_parametrics(\"Machine Learning - Classification\", y_valid, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_parametrics(\"Machine Learning - Classification\", y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ViT_TBC_CXR.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
